{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP5yDPbrJVDenmYSfJ/It23",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaswataJash/Satlike/blob/main/Global_Optimization_in_SatLike.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFPg7TcNBx1B"
      },
      "source": [
        "# Download Weighted MaxSAT formulas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbOTlCOfYVIm"
      },
      "source": [
        "!pip install gdown==3.6.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg2yNNTvY6hz"
      },
      "source": [
        "#downloading from my personal Google drive\n",
        "import gdown\n",
        "gdown.download('https://drive.google.com/uc?id=1MO34-v5jO2FlgDjyTjIpuMznOTkWYLY0', 'mse17-incomplete-weighted-benchmarks.zip', quiet=False) #418MB\n",
        "gdown.download('https://drive.google.com/uc?id=1kBVV3VFQXFPyVnu4jmtQRJz6SH5PBuFC', 'ms18_incomplete_wt.zip', quiet=False) #780MB\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xK2fjTrZS9W"
      },
      "source": [
        "import shutil\n",
        "import time\n",
        "\n",
        "#unpacking of this zip file may take more than 30 seconds\n",
        "start_time_of_unpacking = time.time()\n",
        "shutil.unpack_archive('mse17-incomplete-weighted-benchmarks.zip', '.')\n",
        "print(\"total time taken for unpacking = %s in seconds\" % (time.time() - start_time_of_unpacking))\n",
        "\n",
        "start_time_of_unpacking = time.time()\n",
        "shutil.unpack_archive('ms18_incomplete_wt.zip', '.')\n",
        "print(\"total time taken for unpacking = %s in seconds\" % (time.time() - start_time_of_unpacking))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GgUQ0I4cLGs"
      },
      "source": [
        "import glob\n",
        "import pprint\n",
        "formula_files17 = glob.glob('/content/mse17-incomplete-weighted-benchmarks' + '/**/*.wcnf.gz', recursive=True)\n",
        "#pprint.pprint(formula_files17)\n",
        "print(\"total formula17 file count=%s\" % (len(formula_files17)))\n",
        "formula_files18 = glob.glob('/content/maxsat_instances/ms_evals/MS18/mse18-incomplete-weighted-benchmarks' + '/**/*.wcnf.gz', recursive=True)\n",
        "#pprint.pprint(formula_files18)\n",
        "print(\"total formula18 file count=%s\" % (len(formula_files18)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE3tSD-OY3gd"
      },
      "source": [
        "import gdown\n",
        "gdown.download(\"https://drive.google.com/uc?id=1OEFyZ9TErSWUr8dx5f5oMVL3shNyWKZU\", '2017_results_incomplete_weighted_300s.html', quiet=False)\n",
        "gdown.download(\"https://drive.google.com/uc?id=1SJ2IWED4Ob-H7emgSFgdPpb62avSOF_y\", '2018_results_incomplete_weighted_300s.html', quiet=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SU-hRiCcZw_"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "table_MN_2017 = pd.read_html('2017_results_incomplete_weighted_300s.html')\n",
        "df_2017 = table_MN_2017[0]\n",
        "df_2017.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKW6Ck2CEhWl"
      },
      "source": [
        "def df_table_clean_for_2017_res(x):\n",
        "    if x.rfind('/') > 0:\n",
        "        return x[x.rfind('/')+1:]\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "df_2017['Benchmark'] = df_2017['Benchmark'].map(df_table_clean_for_2017_res)\n",
        "df_2017.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMKVpBcLOmBE"
      },
      "source": [
        "difficult_problems_of_2017_benchmarks = []\n",
        "for index, row in df_2017.iterrows():\n",
        "    count_of_no_sol = 0\n",
        "    for col in df_2017.columns:\n",
        "        if row[col] == '0.0 (-)':\n",
        "            count_of_no_sol += 1\n",
        "    \n",
        "    if count_of_no_sol >= 3:\n",
        "        print(row['Benchmark'])\n",
        "        difficult_problems_of_2017_benchmarks.append(row['Benchmark'])\n",
        "\n",
        "print(\"num of difficult problem of 2017 benchmark =\", len(difficult_problems_of_2017_benchmarks))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJXcEmCLfLR3"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "table_MN_2018 = pd.read_html('2018_results_incomplete_weighted_300s.html')\n",
        "df_2018 = table_MN_2018[0]\n",
        "df_2018.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qsnIBunfUdA"
      },
      "source": [
        "difficult_problems_of_2018_benchmarks = []\n",
        "for index, row in df_2018.iterrows():\n",
        "    count_of_no_sol = 0\n",
        "    for col in df_2018.columns:\n",
        "        if row[col] == '0.0 (-)':\n",
        "            count_of_no_sol += 1\n",
        "    \n",
        "    if count_of_no_sol >= 3:\n",
        "        print(row['Benchmark'])\n",
        "        difficult_problems_of_2018_benchmarks.append(row['Benchmark'])\n",
        "\n",
        "print(\"num of difficult problem of 2018 benchmark =\", len(difficult_problems_of_2018_benchmarks))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyQ1k4gO_ulo"
      },
      "source": [
        "# Satlike Git code download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7MwhXZziUnm"
      },
      "source": [
        "!rm -Rf Satlike\n",
        "!git clone https://github.com/ShaswataJash/Satlike.git\n",
        "%cd /content/Satlike/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmtmwiidDj_t"
      },
      "source": [
        "# SWIG installation for python interface of C++ Satlike"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHGRJAJnn3_M"
      },
      "source": [
        "!wget http://prdownloads.sourceforge.net/swig/swig-4.0.2.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTAgbpVqxU98"
      },
      "source": [
        "!gunzip swig-4.0.2.tar.gz\n",
        "!tar -xvf swig-4.0.2.tar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axnr3a2l1lmn"
      },
      "source": [
        "%cd swig-4.0.2/\n",
        "!./configure\n",
        "!make\n",
        "!make install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDOVypRl665X"
      },
      "source": [
        "%cd /content/Satlike/\n",
        "!swig -c++ -python satlikew.i\n",
        "!cat satlikew.i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_VRCQ6eD8dO"
      },
      "source": [
        "%%writefile satlikew.cpp\n",
        "\n",
        "#include \"basis_pms.h\"\n",
        "#include \"pms.h\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NbJrGBL3173"
      },
      "source": [
        "%%writefile setup.py\n",
        "\n",
        "#!/usr/bin/env python\n",
        "\n",
        "\"\"\"\n",
        "setup.py file for satlikew\n",
        "\"\"\"\n",
        "\n",
        "from distutils.core import setup, Extension\n",
        "\n",
        "#https://stackoverflow.com/questions/1676384/how-to-pass-flag-to-gcc-in-python-setup-py-script\n",
        "satlikew_module = Extension('_satlikew',\n",
        "                           sources=['satlikew_wrap.cxx', 'satlikew.cpp'],\n",
        "                           #extra_compile_args=['-fsanitize=address -fsanitize=pointer-compare -fsanitize=pointer-subtract -fsanitize=leak -fsanitize=undefined']\n",
        "                           #extra_link_args=['-fsanitize=address -fsanitize=pointer-compare -fsanitize=pointer-subtract -fsanitize=leak -fsanitize=undefined']\n",
        "                           )\n",
        "\n",
        "setup (name = 'satlikew',\n",
        "       version = '0.1',\n",
        "       author      = \"Shaswata Jash\",\n",
        "       description = \"\"\"To interact with SatLike3.0 algorithm from python\"\"\",\n",
        "       ext_modules = [satlikew_module],\n",
        "       py_modules = [\"satlikew\"],\n",
        "       )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq1075DU7z0v"
      },
      "source": [
        "#refer http://www.swig.org/Doc4.0/Python.html#Python_nn20\n",
        "!python setup.py build_ext --inplace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFSKo7mzE-hG"
      },
      "source": [
        "!ls -l /content/Satlike/_satlikew.cpython-37m-x86_64-linux-gnu.so"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYOFgFM8Y39z"
      },
      "source": [
        "!ldd /content/Satlike/_satlikew.cpython-37m-x86_64-linux-gnu.so"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zel6-wgZ24NI"
      },
      "source": [
        "# Different scoring schemes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo3oR4JM22Cx"
      },
      "source": [
        "class UnsatSatSeparateScoring:\n",
        "    def __init__(self, s):\n",
        "        self.satlike = s\n",
        "        self.feasible_sol_found = False\n",
        "        self.num_of_times_sat_sc = 0\n",
        "        self.sat_sc_fract_sum = 0.0\n",
        "        self.num_of_times_unsat_hc = 0\n",
        "        self.unsat_hc_fract_sum = 0.0\n",
        "        self.recent_score = 0.0\n",
        "\n",
        "    def update_score(self, result):\n",
        "        if (result >= 0):\n",
        "            self.feasible_sol_found = True\n",
        "\n",
        "        if (result >= 0):\n",
        "            self.num_of_times_sat_sc += 1\n",
        "            self.recent_score = (self.satlike.get_total_soft_weight() - result)/self.satlike.get_total_soft_weight()\n",
        "            self.sat_sc_fract_sum += self.recent_score\n",
        "        else:\n",
        "            self.num_of_times_unsat_hc += 1\n",
        "            self.recent_score = (result / self.satlike.get_num_hclauses()) #recall in this case, result itself will be -ve\n",
        "            self.unsat_hc_fract_sum += self.recent_score\n",
        "\n",
        "    def get_recent_score(self):\n",
        "        #we are negating the final score because we have to minimize the score\n",
        "        return -self.recent_score\n",
        "\n",
        "    def get_final_score(self):\n",
        "        #we are negating the final score because we have to minimize the score\n",
        "        return -(self.sat_sc_fract_sum / self.num_of_times_sat_sc) if self.feasible_sol_found else -(self.unsat_hc_fract_sum / self.num_of_times_unsat_hc)\n",
        "\n",
        "class OnlySatSoftScoring:\n",
        "    def __init__(self, s):\n",
        "        self.satlike = s\n",
        "        self.iteration = 0\n",
        "        self.sat_sc_fract_sum = 0\n",
        "        self.recent_score = 0\n",
        "\n",
        "    def update_score(self, result):\n",
        "        self.recent_score = self.satlike.get_soft_unsat_weight_before_flip()/self.satlike.get_total_soft_weight()\n",
        "        self.sat_sc_fract_sum += self.recent_score\n",
        "        self.iteration += 1\n",
        "\n",
        "    def get_recent_score(self):\n",
        "        return self.recent_score\n",
        "\n",
        "    def get_final_score(self):\n",
        "        assert (SEARCH_PER_EPISODE-1) == self.iteration, \"SEARCH_PER_EPISODE=%s self.iteration=%s\" % (SEARCH_PER_EPISODE,self.iteration)\n",
        "        return (self.sat_sc_fract_sum / self.iteration)\n",
        "\n",
        "class SatSoftWithUnsatHWPenaltyScoringNormalized:\n",
        "    def __init__(self, s):\n",
        "        self.satlike = s\n",
        "        self.iteration = 0\n",
        "        self.sat_sc_fract_sum = 0\n",
        "        self.unsat_hc_fract_sum = 0\n",
        "        self.num_of_times_unsat_hc = 0\n",
        "        self.recent_score = 0.0\n",
        "\n",
        "    def update_score(self, result):\n",
        "        self.recent_score = self.satlike.get_soft_unsat_weight_before_flip()/self.satlike.get_total_soft_weight()\n",
        "        self.sat_sc_fract_sum += self.recent_score\n",
        "        self.iteration += 1\n",
        "        \n",
        "        if(result < 0):\n",
        "            hw_penalty = abs(result / self.satlike.get_num_hclauses()) #recall in this case, result itself will be -ve\n",
        "            #self.recent_score += (1 + hw_penalty) \n",
        "            self.recent_score += hw_penalty \n",
        "            self.unsat_hc_fract_sum += hw_penalty\n",
        "            self.num_of_times_unsat_hc += 1\n",
        "\n",
        "    def get_recent_score(self):\n",
        "        return self.recent_score\n",
        "\n",
        "    def get_final_score(self):\n",
        "        assert (SEARCH_PER_EPISODE-1) == self.iteration, \"SEARCH_PER_EPISODE=%s self.iteration=%s\" % (SEARCH_PER_EPISODE,self.iteration)\n",
        "        return (self.sat_sc_fract_sum / self.iteration) + (self.unsat_hc_fract_sum / self.num_of_times_unsat_hc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdtO1EivNWsy"
      },
      "source": [
        "# decompressing formula files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqK0OgQIzNwX"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "def decompress_formula_file(gzipped_file_name, VERBOSITY=0):\n",
        "    \n",
        "    work_dir = '/tmp/decompressed_formula'\n",
        "    try: \n",
        "        os.mkdir(work_dir) \n",
        "    except OSError as error: \n",
        "        pass\n",
        "      \n",
        "    filename = os.path.split(gzipped_file_name)[-1]\n",
        "    filename = re.sub(r\"\\.gz$\", \"\", filename, flags=re.IGNORECASE)\n",
        "    decompressed_filename = os.path.join(work_dir, filename)\n",
        "\n",
        "    if VERBOSITY > 0: print(\"decompressed_filename = %s\" % (decompressed_filename))\n",
        "    #refer: https://stackoverflow.com/questions/55040442/how-to-register-gz-format-in-shutil-register-archive-format-to-use-same-format\n",
        "    with gzip.open(gzipped_file_name, 'rb') as f_in: \n",
        "        with open(decompressed_filename, 'wb') as f_out:\n",
        "            shutil.copyfileobj(f_in, f_out)\n",
        "\n",
        "    return decompressed_filename\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gto4jA9n6s1o"
      },
      "source": [
        "# Example implementation of SATLike algorithm "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJXydw-UFd1s"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import satlikew\n",
        "import time\n",
        "import shutil\n",
        "import re\n",
        "import gzip\n",
        "import math\n",
        "from statistics import mean \n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import pprint\n",
        "\n",
        "\n",
        "def draw_plots(accumulated_scores,result_emitted_after, score_at_when_result_emitted, CHUNK_LEN):\n",
        "    fig = plt.figure(figsize=(18,6))\n",
        "    plt.plot([x for x in range(len(accumulated_scores))], accumulated_scores)\n",
        "    plt.scatter(result_emitted_after, score_at_when_result_emitted, color='red')\n",
        "            \n",
        "    number_of_chunks = len(accumulated_scores) // CHUNK_LEN\n",
        "    residual_chunk = True if len(accumulated_scores) % CHUNK_LEN > 0 else False\n",
        "    if residual_chunk:\n",
        "        number_of_chunks += 1\n",
        "    prev_mean = None\n",
        "    mean_diff = ''\n",
        "    for i in range(number_of_chunks):\n",
        "        start_of_chunk_index = i*CHUNK_LEN\n",
        "        scores_in_chunk = accumulated_scores[start_of_chunk_index: (start_of_chunk_index+CHUNK_LEN)]\n",
        "        avg_score_of_chunk = mean(scores_in_chunk)\n",
        "        if prev_mean != None:\n",
        "            mean_diff += ('%s ' % ((avg_score_of_chunk - prev_mean)/prev_mean))\n",
        "        prev_mean = avg_score_of_chunk\n",
        "        plt.plot([start_of_chunk_index,start_of_chunk_index+len(scores_in_chunk)],[avg_score_of_chunk,avg_score_of_chunk], color='magenta', linestyle=\"--\")\n",
        "    fig.show()\n",
        "\n",
        "def cross_over_style1(my_satlike, rand_gen, VERBOSITY=0):\n",
        "    different = 0\n",
        "    for x in range(my_satlike.get_num_vars()):\n",
        "        assert (my_satlike.get_init_sol(x+1) == 0) or (my_satlike.get_init_sol(x+1) == 1)\n",
        "        if my_satlike.get_best_sol(x+1) != my_satlike.get_init_sol(x+1):\n",
        "            different += 1\n",
        "            p = rand_gen.uniform(0, 1)\n",
        "            my_satlike.set_init_sol(x+1,\n",
        "                my_satlike.get_best_sol(x+1) if p < 0.80 else (1 - my_satlike.get_best_sol(x+1)))\n",
        "                \n",
        "    if VERBOSITY > 0: print(\"init from crossover-style1 feasible_flag=\", my_satlike.get_feasible_flag_state(), \" different=\", different)\n",
        "    my_satlike.init_with_decimation_stepwise(False, True) #copy_best_sol = False, copy_init_sol = True\n",
        "\n",
        "def cross_over_style2(my_satlike, rand_gen, VERBOSITY=0):\n",
        "    for x in range(my_satlike.get_num_vars()):\n",
        "        p = rand_gen.uniform(0, 1)\n",
        "        my_satlike.set_init_sol(x+1,\n",
        "            my_satlike.get_best_sol(x+1) if p < 0.10 else (1 - my_satlike.get_best_sol(x+1)))\n",
        "                \n",
        "    if VERBOSITY > 0: print(\"init from crossover-style2 feasible_flag=\", my_satlike.get_feasible_flag_state())\n",
        "    my_satlike.init_with_decimation_stepwise(False, True) #copy_best_sol = False, copy_init_sol = True\n",
        "\n",
        "def cross_over_style3(my_satlike, rand_gen, flipped_var_stat, VERBOSITY=0):\n",
        "    from_var_red_stat = 0\n",
        "    for x in range(my_satlike.get_num_vars()):\n",
        "        if (x+1) in flipped_var_stat:\n",
        "            if (flipped_var_stat[x+1][0] < 0) or (flipped_var_stat[x+1][1] < 0):\n",
        "                my_satlike.set_init_sol(x+1, 0 if flipped_var_stat[x+1][0] < flipped_var_stat[x+1][1] else 1)\n",
        "                from_var_red_stat += 1\n",
        "                continue\n",
        "        p = rand_gen.uniform(0, 1)\n",
        "        my_satlike.set_init_sol(x+1, 0 if p < 0.5 else 1)\n",
        "\n",
        "    if VERBOSITY > 0: print(\"init from crossover-style3 feasible_flag=\", my_satlike.get_feasible_flag_state() , \" from_var_red_stat=\", from_var_red_stat)\n",
        "    my_satlike.init_with_decimation_stepwise(False, True) #copy_best_sol = False, copy_init_sol = True\n",
        "\n",
        "\n",
        "def determine_var_to_score_reduction_stat (total_var_count, flipped_var_to_score_red_stat, VERBOSITY=0):\n",
        "\n",
        "    if len(flipped_var_to_score_red_stat) == 0:\n",
        "        return {}\n",
        "\n",
        "    flipped_var_stat = {}\n",
        "    for x in range(total_var_count):\n",
        "        key = x+1\n",
        "\n",
        "        if not (key in flipped_var_to_score_red_stat):\n",
        "            if (VERBOSITY > 1): print(\"var=%s is never considered for flipping\" % (key))\n",
        "            continue\n",
        "                \n",
        "        val = flipped_var_to_score_red_stat[key]\n",
        "        flipped_var_stat[key] = [0,0]\n",
        "\n",
        "        if val[0][1] == 0:\n",
        "            if (VERBOSITY > 1): print(\"var=%s for val=0 has never fliped into\" % (key))\n",
        "        else:\n",
        "            flipped_var_stat[key][0] = val[0][0] / val[0][1]\n",
        "            if (VERBOSITY > 1) and (flipped_var_stat[key][0] < 0):\n",
        "                print(\"var=%s for val=0 avg_red=%s (sum=%s, count=%s)\" % (key, flipped_var_stat[key][0], val[0][0], val[0][1]))\n",
        "\n",
        "        if val[1][1] == 0:\n",
        "            if (VERBOSITY > 1): print(\"var=%s for val=1 has never fliped into\" % (key))\n",
        "        else:\n",
        "            flipped_var_stat[key][1] = val[1][0] / val[1][1]\n",
        "            if (VERBOSITY > 1) and (flipped_var_stat[key][1] < 0):\n",
        "                print(\"var=%s for val=1 avg_red=%s (sum=%s, count=%s)\" % (key, flipped_var_stat[key][1], val[1][0], val[1][1]))\n",
        "\n",
        "    return flipped_var_stat\n",
        "\n",
        "def satlike_execution(decompressed_filename, seed, initial_max_flip = None, adaptive_search=True, max_non_improve_flip=None, \n",
        "                      ext_hd_count=None, ext_smooth_probab=None, ext_hinc=None, ext_softclause_weight=None, lower_unsat_weight_acheive_hook = None,\n",
        "                      time_budget_s = 300, premptive_episode_closure=False, init_sol_from_crossover=\"\", VERBOSITY = 0, draw_figure=False, plot_solution_if_new=False):\n",
        "\n",
        "    CHUNK_LEN = 1000000\n",
        "     \n",
        "    satlike = satlikew.Satlike()\n",
        "    if VERBOSITY > 0: print(\"satlike object created %s sec before\" % (satlike.get_runtime()))\n",
        "    try:\n",
        "\n",
        "        satlike.build_instance(decompressed_filename)\n",
        "\n",
        "        if initial_max_flip != None:\n",
        "            satlike.set_initial_max_flip(initial_max_flip)\n",
        "        satlike.algo_init(seed, 0, True, todebug=False) #RAND_GEN_TYPE rType=MINSTD=0\n",
        "        if VERBOSITY > 0: print(\"formula num_of_var=%s num_of_hclause=%s num_of_sclause=%s top_clause_wt=%s total_soft_wt=%s\"\n",
        "                              % (satlike.get_num_vars(), satlike.get_num_hclauses(), satlike.get_num_sclauses(), \n",
        "                                 satlike.get_top_clause_weight(), satlike.get_total_soft_weight()))\n",
        "\n",
        "        last_soft_unsat_weight = satlike.get_total_soft_weight()+1\n",
        "\n",
        "        start_time = time.time()\n",
        "        break_from_outer_loop = False\n",
        "        iteration_count=0\n",
        "        iteration_count_when_lowest_unsat_weight_acheived=-1\n",
        "        improvement_iteration = 0\n",
        "\n",
        "        flipped_var_to_score_red_stat = {}\n",
        "        r = random.Random(seed)\n",
        "        exploit_cycle = True\n",
        "        changing_seed = seed\n",
        "\n",
        "        if plot_solution_if_new:\n",
        "            found_solution_count = defaultdict(int)\n",
        "\n",
        "        while break_from_outer_loop == False:\n",
        "            \n",
        "            if (len(init_sol_from_crossover) > 0) and (last_soft_unsat_weight < (satlike.get_total_soft_weight()+1)):\n",
        "\n",
        "                if init_sol_from_crossover == 'style1':\n",
        "                    cross_over_style1(satlike, r, VERBOSITY)\n",
        "                    \n",
        "                elif init_sol_from_crossover == 'style2':\n",
        "                    cross_over_style2(satlike, r, VERBOSITY)\n",
        "                    \n",
        "                elif init_sol_from_crossover == 'style3':\n",
        "                    my_flipped_var_stat = determine_var_to_score_reduction_stat(satlike.get_num_vars(), flipped_var_to_score_red_stat, VERBOSITY)\n",
        "                    cross_over_style3(satlike, r, my_flipped_var_stat, VERBOSITY)\n",
        "                    \n",
        "                elif init_sol_from_crossover == 'style4':\n",
        "                    satlike.init_with_decimation_stepwise(True, False) #copy_best_sol = True, copy_init_sol = False\n",
        "\n",
        "                elif init_sol_from_crossover == 'style5':\n",
        "                    if exploit_cycle:\n",
        "                        satlike.init_with_decimation_stepwise(True, False) #copy_best_sol = True, copy_init_sol = False\n",
        "                    else:\n",
        "                        changing_seed += 4096\n",
        "                        satlike.algo_init(changing_seed, 0, True, todebug=False) #RAND_GEN_TYPE rType=MINSTD=0, as seeds are changing rang-generator has to be recreated\n",
        "                        satlike.init_with_decimation_stepwise(False, False)\n",
        "                    if VERBOSITY > 0: print(\"init exploit_cycle=\", exploit_cycle, \" current_seed=\", changing_seed)\n",
        "                               \n",
        "            else:\n",
        "                if VERBOSITY > 0: print(\"init from decimation feasible_flag=\", satlike.get_feasible_flag_state())\n",
        "                satlike.init_with_decimation_stepwise(False, False)\n",
        "            \n",
        "            current_step = 1\n",
        "            scorer = SatSoftWithUnsatHWPenaltyScoringNormalized(satlike)\n",
        "\n",
        "            if draw_figure or premptive_episode_closure:\n",
        "                accumulated_scores = []\n",
        "                result_emitted_after = []\n",
        "                score_at_when_result_emitted = []\n",
        "                if plot_solution_if_new:\n",
        "                    starting_sol_bitstr = ''.join([str(satlike.get_current_sol(x+1)) for x in range(satlike.get_num_vars())])\n",
        "\n",
        "            chunk_index = 0\n",
        "            prev_mean = None\n",
        "\n",
        "            flipped_var_in_prev_step = -1\n",
        "            fliped_val_of_var = -1\n",
        "            prev_score_in_last_flip = -1\n",
        "\n",
        "            any_improvement_found_in_current_episode = False\n",
        "            \n",
        "            #for (unsigned int current_step = 1; current_step<get_max_flips(); ++current_step)\n",
        "            #to keep the looping as original C++ code, condition check is done against (satlike.get_max_flips()-1)\n",
        "            while current_step < (satlike.get_max_flips()-1):\n",
        "                current_step += 1\n",
        "                iteration_count += 1\n",
        "                result = satlike.local_search_stepwise(\n",
        "                    ext_hd_count          if (ext_hd_count != None) else satlike.get_hd_count_threshold(), \n",
        "                    ext_smooth_probab     if (ext_smooth_probab != None) else satlike.get_smooth_probability(), \n",
        "                    ext_hinc              if (ext_hinc != None) else satlike.get_h_inc(), \n",
        "                    ext_softclause_weight if (ext_softclause_weight != None) else satlike.get_softclause_weight_threshold(), \n",
        "                    max_non_improve_flip  if (max_non_improve_flip != None) else satlike.get_max_non_improve_flip(),\n",
        "                    current_step,\n",
        "                    adaptive_search,\n",
        "                    0) #verbose_level=0\n",
        "\n",
        "                scorer.update_score(result)\n",
        "                current_score = scorer.get_recent_score()\n",
        "\n",
        "                if init_sol_from_crossover == 'style3':\n",
        "                    if flipped_var_in_prev_step != -1:\n",
        "                        if not (flipped_var_in_prev_step in flipped_var_to_score_red_stat):\n",
        "                            flipped_var_to_score_red_stat[flipped_var_in_prev_step] = {0:[0,0], 1:[0,0]} #list structure [sum_of_reduction_of_score,count]\n",
        "                        flipped_var_to_score_red_stat[flipped_var_in_prev_step][fliped_val_of_var][0] += (prev_score_in_last_flip - current_score)\n",
        "                        flipped_var_to_score_red_stat[flipped_var_in_prev_step][fliped_val_of_var][1] += 1\n",
        "                    prev_score_in_last_flip = current_score\n",
        "\n",
        "                    flipped_var_in_prev_step = satlike.get_flipped_var()\n",
        "                    fliped_val_of_var = satlike.get_current_sol(flipped_var_in_prev_step)\n",
        "                    assert (fliped_val_of_var == 0) or (fliped_val_of_var == 1)\n",
        "\n",
        "                if draw_figure or premptive_episode_closure: accumulated_scores.append(current_score)\n",
        "              \n",
        "                if (result >= 0) :\n",
        "\n",
        "                    if (result < last_soft_unsat_weight):\n",
        "                        any_improvement_found_in_current_episode = True\n",
        "                        improvement_iteration += 1\n",
        "                        if VERBOSITY > 0: print(\"iteration_count=%s opt_unsat_weight = %s score=%s time-taken in sec=%s improvement_iteration=%s\" % \n",
        "                            (iteration_count, result, current_score, time.time() - start_time, improvement_iteration), flush=True)\n",
        "                        if lower_unsat_weight_acheive_hook != None:\n",
        "                            working_sol = [satlike.get_best_sol(x+1) for x in range(satlike.get_num_vars())]\n",
        "                            lower_unsat_weight_acheive_hook(result, working_sol, improvement_iteration, VERBOSITY)\n",
        "                        last_soft_unsat_weight = result\n",
        "                        iteration_count_when_lowest_unsat_weight_acheived = iteration_count\n",
        "\n",
        "                    if draw_figure:\n",
        "                        if plot_solution_if_new:\n",
        "                            if not (starting_sol_bitstr in found_solution_count):\n",
        "                                result_emitted_after.append(len(accumulated_scores)-1)\n",
        "                                score_at_when_result_emitted.append(current_score)\n",
        "                            found_solution_count[starting_sol_bitstr] += 1 \n",
        "                        else:\n",
        "                            result_emitted_after.append(len(accumulated_scores)-1)\n",
        "                            score_at_when_result_emitted.append(current_score)\n",
        "\n",
        "                    if last_soft_unsat_weight == 0:\n",
        "                        break_from_outer_loop = True\n",
        "                        break\n",
        "            \n",
        "                if time.time() - start_time > time_budget_s:\n",
        "                    if VERBOSITY > 0: print(\"Experiment time (%s) exhausted, iteration_count=%s\" % (time_budget_s, iteration_count), flush=True)\n",
        "                    break_from_outer_loop = True\n",
        "                    break\n",
        "\n",
        "                if premptive_episode_closure and (len(accumulated_scores) % CHUNK_LEN == 0):\n",
        "                    start_of_chunk_index = chunk_index*CHUNK_LEN\n",
        "                    scores_in_chunk = accumulated_scores[start_of_chunk_index: (start_of_chunk_index+CHUNK_LEN)]\n",
        "                    avg_score_of_chunk = mean(scores_in_chunk)\n",
        "                    if prev_mean != None:\n",
        "                        fract_diff = ((avg_score_of_chunk - prev_mean)/prev_mean)\n",
        "                        percent_diff = fract_diff * 100.0\n",
        "                        if VERBOSITY > 0: print(\"percent_diff=%s avg_score_of_chunk=%s prev_mean=%s iteration_count=%s\" \n",
        "                                  % (percent_diff, avg_score_of_chunk, prev_mean, iteration_count), flush=True)\n",
        "                        if math.floor(abs(percent_diff)) <= 1.0:\n",
        "                            break\n",
        "\n",
        "                    prev_mean = avg_score_of_chunk\n",
        "                    chunk_index += 1\n",
        "\n",
        "                if plot_solution_if_new:\n",
        "                    flipped_var_in_prev_step = satlike.get_flipped_var()\n",
        "                    fliped_val_of_var = satlike.get_current_sol(flipped_var_in_prev_step)\n",
        "                    assert (fliped_val_of_var == 0) or (fliped_val_of_var == 1)\n",
        "                    \n",
        "                    index_to_replace = flipped_var_in_prev_step-1\n",
        "                    char_to_replace = '1' if starting_sol_bitstr[flipped_var_in_prev_step-1] == '0' else '0'\n",
        "                    starting_sol_bitstr = starting_sol_bitstr[:index_to_replace] + char_to_replace + starting_sol_bitstr[index_to_replace+1:]\n",
        "                    assert starting_sol_bitstr[flipped_var_in_prev_step-1] == str(fliped_val_of_var)\n",
        "\n",
        "            \n",
        "            if draw_figure: draw_plots(accumulated_scores, result_emitted_after, score_at_when_result_emitted,CHUNK_LEN)\n",
        "            if VERBOSITY > 0: print(\"Episode completed, iteration_count=%s time-taken in sec=%s\" % (iteration_count, time.time() - start_time), flush=True)\n",
        "            \n",
        "            if (init_sol_from_crossover == 'style5') and (last_soft_unsat_weight < (satlike.get_total_soft_weight()+1)):\n",
        "                exploit_cycle = False if (False == any_improvement_found_in_current_episode) else True\n",
        "\n",
        "    except Exception:\n",
        "        ex_type = sys.exc_info()[0]\n",
        "        ex_value= sys.exc_info()[1]\n",
        "        print(\"Exception type: %s Exception message: %s\" %(ex_type.__name__,ex_value),flush=True)\n",
        "    finally:\n",
        "        satlike.free_memory()\n",
        "\n",
        "    del satlike\n",
        "\n",
        "    return iteration_count_when_lowest_unsat_weight_acheived,last_soft_unsat_weight\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH7jI5yYPFew"
      },
      "source": [
        "formula_for_experiment1 = '/content/mse17-incomplete-weighted-benchmarks/correlation-clustering-Rounded_CorrelationClustering_Vowel_BINARY_N760_D0.200.wcnf.gz'\n",
        "formula_for_experiment2 = '/content/mse17-incomplete-weighted-benchmarks/rna-alignment-k100-42-56.rna.pre.wcnf.gz'\n",
        "#formula_for_experiment3 = '/content/mse17-incomplete-weighted-benchmarks/causal-discovery-causal_carpo_8_1000.wcnf.gz'\n",
        "#formula_for_experiment4 = '/content/mse17-incomplete-weighted-benchmarks/correlation-clustering-Rounded_CorrelationClustering_Ecoli_BINARY_N280_D0.200.wcnf.gz'\n",
        " \n",
        "result_for_experiment1_original = satlike_execution(decompress_formula_file(formula_for_experiment1), 1, VERBOSITY=1)\n",
        "assert result_for_experiment1_original[0] == 18719817 #iteration\n",
        "assert result_for_experiment1_original[1] == 91166379 #lowest_unsat_weight\n",
        "\n",
        "result_for_experiment2_original = satlike_execution(decompress_formula_file(formula_for_experiment2), 1, VERBOSITY=1)\n",
        "assert result_for_experiment2_original[0] == 35984 #iteration\n",
        "assert result_for_experiment2_original[1] == 1847  #lowest_unsat_weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE0ebRdyXRQ9"
      },
      "source": [
        "\n",
        "formula_for_experiment1 = '/content/mse17-incomplete-weighted-benchmarks/correlation-clustering-Rounded_CorrelationClustering_Vowel_BINARY_N760_D0.200.wcnf.gz'\n",
        "formula_for_experiment2 = '/content/mse17-incomplete-weighted-benchmarks/rna-alignment-k100-42-56.rna.pre.wcnf.gz'\n",
        "formula_for_experiment3 = '/content/mse17-incomplete-weighted-benchmarks/causal-discovery-causal_carpo_8_1000.wcnf.gz'\n",
        "#formula_for_experiment = '/content/mse17-incomplete-weighted-benchmarks/correlation-clustering-Rounded_CorrelationClustering_Ecoli_BINARY_N280_D0.200.wcnf.gz'\n",
        "\n",
        " \n",
        "result_for_experiment1_with_premptive_episode = satlike_execution(decompress_formula_file(formula_for_experiment1), 1, premptive_episode_closure=True,\n",
        "                                                              init_sol_from_crossover='style5', VERBOSITY=1, draw_figure=True)\n",
        "\n",
        "'''\n",
        "assert result_for_experiment1_with_premptive_episode[0] == 9088683 #iteration\n",
        "assert result_for_experiment1_with_premptive_episode[1] == 93351646 #lowest_unsat_weight\n",
        "\n",
        "result_for_experiment2_with_premptive_episode = satlike_execution(decompress_formula_file(formula_for_experiment2), 1, premptive_episode_closure=True,\n",
        "                                                              init_sol_from_crossover='style5', time_budget_s=600, VERBOSITY=1, draw_figure=True)\n",
        "#assert result_for_experiment2_with_premptive_episode[0] == 8002246 #iteration\n",
        "#assert result_for_experiment2_with_premptive_episode[1] == 1843 #lowest_unsat_weight\n",
        "\n",
        "\n",
        "result_for_experiment3_with_premptive_episode = satlike_execution(decompress_formula_file(formula_for_experiment3), 1, premptive_episode_closure=True,\n",
        "                                                              init_sol_from_crossover='style5', time_budget_s=900, VERBOSITY=1, draw_figure=True)\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG-B9OXIdpHD"
      },
      "source": [
        "# Ray-tune experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlYoaCdvHkMt"
      },
      "source": [
        "!whoami\n",
        "!pwd\n",
        "!python -V\n",
        "!pip install ray[tune]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U0tiG6cv3DA"
      },
      "source": [
        "!rm -Rf /tmp/decompressed_formula\n",
        "!mkdir /tmp/decompressed_formula\n",
        "#!ray start --help\n",
        "#Without explicit information about binding dashboard-host to 127.0.0.1, dashboard can't be connected in google-colab\n",
        "!ray start --head --port=6379 --object-manager-port=8076 --include-dashboard True --dashboard-host 127.0.0.1 --dashboard-port 8265 &"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i4USMy-Dyz_"
      },
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(8265)\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyitxogWNFzM"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ~/ray_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-M-i6f0QlmS"
      },
      "source": [
        "CHOSEN_METRIC = 'episode_unsat_weight'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm5cgsCLrpOk"
      },
      "source": [
        "import ray\n",
        "from ray import tune\n",
        "import satlikew\n",
        "import time\n",
        "import random\n",
        "\n",
        "class GlobalOptimInSATLike(tune.Trainable):\n",
        "    def setup(self, config):\n",
        "        self.start_time = time.time()\n",
        "        if config['verbosity'] > 0: print(\"object-id=%s setup with config=%s\" % (id(self),config))\n",
        "        self.config = config\n",
        "        self.satlike = satlikew.Satlike()\n",
        "        self.satlike.build_instance(self.config['decomp_file'])\n",
        "        self.changing_seed = (int)(config['random_seed'])\n",
        "        self.satlike.algo_init(self.changing_seed, 0, True, todebug=False) #RAND_GEN_TYPE rType=MINSTD=0\n",
        "        self.last_soft_unsat_weight = self.satlike.get_total_soft_weight()+1\n",
        "        self.iterations = 0\n",
        "        self.exploit_cycle=True\n",
        "        self.global_algo_cont = True\n",
        "        self.__reset_episode(False)\n",
        "        \n",
        "    def __reset_episode(self, override):\n",
        "        if override:\n",
        "            if self.config['verbosity'] > 0: print(\"init overide\")\n",
        "            self.satlike.init_with_decimation_stepwise(False, True) #copy_best_sol = False, copy_init_sol = True\n",
        "        elif (self.last_soft_unsat_weight < (self.satlike.get_total_soft_weight()+1)):\n",
        "            if self.exploit_cycle:\n",
        "                self.satlike.init_with_decimation_stepwise(True, False) #copy_best_sol = True, copy_init_sol = False\n",
        "            else:\n",
        "                self.changing_seed += 4096\n",
        "                self.satlike.algo_init(self.changing_seed, 0, True, todebug=False) #RAND_GEN_TYPE rType=MINSTD=0, as seeds are changing rang-generator has to be recreated\n",
        "                self.satlike.init_with_decimation_stepwise(False, False)\n",
        "            if self.config['verbosity'] > 0: print(\"init exploit_cycle=\", self.exploit_cycle, \" current_seed=\", self.changing_seed)\n",
        "        else:\n",
        "            if self.config['verbosity'] > 0: print(\"init from decimation feasible_flag=\", self.satlike.get_feasible_flag_state())\n",
        "            self.satlike.init_with_decimation_stepwise(False, False)\n",
        "        \n",
        "        self.current_step = 1\n",
        "        self.scorer = SatSoftWithUnsatHWPenaltyScoringNormalized(self.satlike)\n",
        "\n",
        "        self.accumulated_scores = []\n",
        "        self.chunk_index = 0\n",
        "        self.prev_mean = None\n",
        "\n",
        "        self.any_improvement_found_in_current_episode = False\n",
        "\n",
        "    def step(self):  # This is called iteratively.\n",
        "\n",
        "        improvement_found_in_current_chunk = False\n",
        "        \n",
        "        while self.current_step < self.satlike.get_max_flips() and self.global_algo_cont:\n",
        "            self.current_step += 1\n",
        "            self.iterations += 1\n",
        "            result = self.satlike.local_search_stepwise(\n",
        "                (int)(self.config['hd_count_threshold']), \n",
        "                self.config['smooth_probability'], \n",
        "                (int)(self.config['h_inc']), \n",
        "                (int)(self.config['softclause_weight_threshold']), \n",
        "                self.satlike.get_max_non_improve_flip(),\n",
        "                self.current_step,\n",
        "                True, #adaptive_search=True\n",
        "                0) #verbose_level=0\n",
        "\n",
        "            self.scorer.update_score(result)\n",
        "            current_score = self.scorer.get_recent_score()\n",
        "            if self.config['premptive_episode_closure']: self.accumulated_scores.append(current_score)\n",
        "            \n",
        "            if (result >= 0) and (result < self.last_soft_unsat_weight):\n",
        "                if self.config['verbosity'] > 0: print(\"iterations=%s unsat_soft=%s score=%s time=%s\" \n",
        "                                                % (self.iterations, result, current_score, time.time() - self.start_time))\n",
        "                self.last_soft_unsat_weight = result\n",
        "                improvement_found_in_current_chunk = True\n",
        "                self.any_improvement_found_in_current_episode = True\n",
        "                if self.last_soft_unsat_weight == 0:\n",
        "                    self.global_algo_cont = False\n",
        "\n",
        "            if self.config['premptive_episode_closure'] and (len(self.accumulated_scores) % self.config['CHUNK_LEN'] == 0):\n",
        "                start_of_chunk_index = self.chunk_index*self.config['CHUNK_LEN']\n",
        "                scores_in_chunk = self.accumulated_scores[start_of_chunk_index: (start_of_chunk_index+self.config['CHUNK_LEN'])]\n",
        "                avg_score_of_chunk = mean(scores_in_chunk)\n",
        "                if self.prev_mean != None:\n",
        "                    fract_diff = ((avg_score_of_chunk - self.prev_mean)/self.prev_mean)\n",
        "                    percent_diff = fract_diff * 100.0\n",
        "                    if self.config['verbosity'] > 0: print(\"percent_diff=%s avg_score_of_chunk=%s prev_mean=%s iteration_count=%s\" \n",
        "                                % (percent_diff, avg_score_of_chunk, self.prev_mean, self.iterations), flush=True)\n",
        "                    if math.floor(abs(percent_diff)) <= 1.0:\n",
        "                        self.__reset_episode(False)\n",
        "                        break\n",
        "\n",
        "                self.prev_mean = avg_score_of_chunk\n",
        "                self.chunk_index += 1\n",
        "\n",
        "            if (self.iterations % self.config['CHUNK_LEN']) == 0:\n",
        "                break #on every self.config['CHUNK_LEN'], emit some result so that pertubation logic can be applied frequently\n",
        "\n",
        "        if (self.last_soft_unsat_weight < (self.satlike.get_total_soft_weight()+1)) and (self.current_step >= self.satlike.get_max_flips()):\n",
        "            self.exploit_cycle = False if (False == self.any_improvement_found_in_current_episode) else True\n",
        "            self.__reset_episode(False)\n",
        "\n",
        "        return {CHOSEN_METRIC: self.last_soft_unsat_weight, \n",
        "                \"done\": True if self.last_soft_unsat_weight == 0 else False,\n",
        "                \"should_checkpoint\": improvement_found_in_current_chunk}\n",
        "\n",
        "    def save_checkpoint(self, tmp_checkpoint_dir):\n",
        "        working_sol = []\n",
        "        if self.last_soft_unsat_weight < (self.satlike.get_total_soft_weight()+1):\n",
        "            working_sol = [self.satlike.get_best_sol(x+1) for x in range(self.satlike.get_num_vars())]\n",
        "        return {CHOSEN_METRIC: self.last_soft_unsat_weight, \"solution\": working_sol}\n",
        "\n",
        "    def load_checkpoint(self, checkpointed_data):\n",
        "        if len(checkpointed_data['solution']) == self.satlike.get_num_vars():\n",
        "            if self.config['verbosity'] > 0: print(\"Recevied checkpoint from metric=\", checkpointed_data[CHOSEN_METRIC], \" local last_soft_unsat_weight=\", self.last_soft_unsat_weight)\n",
        "            for x in range(self.satlike.get_num_vars()):\n",
        "                self.satlike.set_init_sol(x+1,checkpointed_data['solution'][x])\n",
        "            self.__reset_episode(True)\n",
        "\n",
        "    def reset_config(self, new_config):\n",
        "        if self.config['verbosity'] > 0: print(\"old config=%s new config=%s\" % (self.config, new_config))\n",
        "        self.config = new_config\n",
        "        return True\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Releases all resources used by this trainable.\n",
        "\n",
        "        Calls ``Trainable.cleanup`` internally. Subclasses should override\n",
        "        ``Trainable.cleanup`` for custom cleanup procedures.\n",
        "        \"\"\"\n",
        "        self.global_algo_cont = False #so that currently ongoing step should exit as quickly as possible\n",
        "\n",
        "        self._result_logger.flush()\n",
        "        self._result_logger.close()\n",
        "        if self._monitor.is_alive():\n",
        "            self._monitor.stop()\n",
        "            self._monitor.join()\n",
        "        self.cleanup()\n",
        "\n",
        "        self._close_logfiles()\n",
        "\n",
        "    def cleanup(self):\n",
        "        self.satlike.free_memory()\n",
        "        del self.satlike"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FePJJJn7V88"
      },
      "source": [
        "from ray.tune.schedulers import PopulationBasedTraining\n",
        "import sys\n",
        "\n",
        "def conduct_tune_experiment_with_PBT(total_exp_time=1200):\n",
        "    ray.shutdown()\n",
        "    ray.init(address='auto', ignore_reinit_error=True)\n",
        "    print('''This cluster consists of {} nodes in total {} CPU resources in total '''.format(len(ray.nodes()), ray.cluster_resources()['CPU']))\n",
        "\n",
        "    #formula_for_experiment = '/content/mse17-incomplete-weighted-benchmarks/correlation-clustering-Rounded_CorrelationClustering_Vowel_BINARY_N760_D0.200.wcnf.gz'\n",
        "    #formula_for_experiment = '/content/mse17-incomplete-weighted-benchmarks/rna-alignment-k100-42-56.rna.pre.wcnf.gz'\n",
        "    formula_for_experiment = '/content/mse17-incomplete-weighted-benchmarks/causal-discovery-causal_carpo_8_1000.wcnf.gz'\n",
        "    #formula_for_experiment = '/content/mse17-incomplete-weighted-benchmarks/correlation-clustering-Rounded_CorrelationClustering_Ecoli_BINARY_N280_D0.200.wcnf.gz'\n",
        "\n",
        "    decompressed_file = decompress_formula_file(formula_for_experiment)\n",
        "\n",
        "    pbt = PopulationBasedTraining(\n",
        "        time_attr=\"training_iteration\",\n",
        "        perturbation_interval=4,\n",
        "\n",
        "        #time_attr='time_total_s',\n",
        "        #perturbation_interval=60.0,\n",
        "        \n",
        "        hyperparam_mutations={\n",
        "            \"hd_count_threshold\": tune.uniform(1 , 100), #hd_count_threshold, default 15\n",
        "            \"smooth_probability\": tune.uniform(0.0000001, 0.1), #smooth_probability, default either .01 or .0000001\n",
        "            \"h_inc\": tune.uniform(1,1000),  #h_inc, default 3 or 300\n",
        "            \"softclause_weight_threshold\" : tune.uniform(0, 2000), #softclause_weight_threshold,  default 0 or 500\n",
        "        },\n",
        "        \n",
        "        synch = False)\n",
        "    \n",
        "    satlike = satlikew.Satlike()\n",
        "    satlike.build_instance(decompressed_file)\n",
        "    satlike.algo_init(1, 0, True, todebug=False)\n",
        "    ext_hd_count = satlike.get_hd_count_threshold() \n",
        "    ext_smooth_probab = satlike.get_smooth_probability()\n",
        "    ext_hinc = satlike.get_h_inc()\n",
        "    ext_softclause_weight = satlike.get_softclause_weight_threshold()\n",
        "    print('ext_hd_count=%s ext_smooth_probab=%s ext_hinc=%s ext_softclause_weight=%s' % \n",
        "          (ext_hd_count,ext_smooth_probab, ext_hinc, ext_softclause_weight))\n",
        "    satlike.free_memory()\n",
        "    del satlike\n",
        "    \n",
        "    NUM_OF_PARALLEL_SAMPLE = (int)(ray.cluster_resources()['CPU'])\n",
        "\n",
        "    try:\n",
        "        analysis = tune.run(\n",
        "            GlobalOptimInSATLike,\n",
        "            name=\"GLOBAL-OPTIM-IN-SatLike-Using-PBT\",\n",
        "            resources_per_trial={\n",
        "                \"cpu\": 1, \n",
        "            },\n",
        "            metric = CHOSEN_METRIC,\n",
        "            mode = 'min',\n",
        "            time_budget_s=total_exp_time,\n",
        "            #num_samples=NUM_OF_PARALLEL_SAMPLE,\n",
        "            num_samples=1,\n",
        "            scheduler=pbt,\n",
        "            reuse_actors=True, #so that satlike current states are not destroyed\n",
        "            config={\n",
        "                \"hd_count_threshold\": ext_hd_count,\n",
        "                \"smooth_probability\": ext_smooth_probab, \n",
        "                \"h_inc\": ext_hinc,  \n",
        "                \"softclause_weight_threshold\" : ext_softclause_weight,\n",
        "                \"decomp_file\": decompressed_file,\n",
        "                \"cross_over_sampling_probability\": 0.5,\n",
        "                \"verbosity\": 1,\n",
        "                \"premptive_episode_closure\": True,\n",
        "                'CHUNK_LEN': 1000000,\n",
        "                \"random_seed\": tune.grid_search([x*123 for x in range(NUM_OF_PARALLEL_SAMPLE)])\n",
        "            },\n",
        "            fail_fast=True,\n",
        "            #progress_reporter = TrialTerminationReporter((int)(ray.cluster_resources()['CPU']))\n",
        "        )\n",
        "\n",
        "        print(\"Best config: %s best_result=%s\" % (analysis.best_config, analysis.best_result))\n",
        "    except:\n",
        "        print(\"Oops! \", sys.exc_info()[0], \" occurred.\")\n",
        "\n",
        "    ray.shutdown()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-3nPlw0XJPW"
      },
      "source": [
        "conduct_tune_experiment_with_PBT()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2933KNechorr"
      },
      "source": [
        "!g++ -O2 -Wall -g -fstack-protector-strong -D_FORTIFY_SOURCE=2 pms.cpp -o pms.out\n",
        "!ldd pms.out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9A7t39Imoky"
      },
      "source": [
        "#!./pms.out -c -r 1 -v 2 -h 814 -t 12 -s 0.00704856 -e 663 -z 1000000  \"/tmp/causal-discovery-causal_carpo_8_1000.wcnf\"\n",
        "#!./pms.out -c -r 1 -v 2 -h 706 -t 18 -s 0.0032607 -e 205  \"/tmp/causal-discovery-causal_carpo_8_1000.wcnf\" #opt_unsat_weight=4505953\n",
        "#!./pms.out -c -r 1 -v 2  \"/tmp/causal-discovery-causal_carpo_8_1000.wcnf\"\t#soft_unsat_weight=4937192\n",
        "\n",
        "#!./pms.out -c -r 1 -v 1  -t 10  -s 0.011881809087992991  -h 45 -e 608 \"/tmp/correlation-clustering-Rounded_CorrelationClustering_Ecoli_BINARY_N280_D0.200.wcnf\" #soft_unsat_weight=33568165\n",
        "#!./pms.out -c -r 1 -v 1  -t 26  -s 0.041293033872572715  -h 38 -e 1253 \"/tmp/correlation-clustering-Rounded_CorrelationClustering_Ecoli_BINARY_N280_D0.200.wcnf\"\n",
        "\n",
        "!./pms.out -c -r 1 -v 1 -t 25 -s 0.06132548484136097 -h 1 -e 938 \"/tmp/correlation-clustering-Rounded_CorrelationClustering_Vowel_BINARY_N760_D0.200.wcnf\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}